{"cells":[{"cell_type":"markdown","source":["## Databrick on GCP BQ posting"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce6c362b-c47a-4f76-847f-6d3705986f18"}}},{"cell_type":"markdown","source":["This unsupported notebook notebook is supporting the posting [**Spark predicate pushdown for Google BigQuery**](https://medium.com/@frank.munz/predicate-pushdown-for-apache-spark-with-google-bigquery-2ad4f9e81e6).\n### Write Spark DF to BQ dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4b337a9f-9a41-4d39-b31d-49223c72362f"}}},{"cell_type":"code","source":["from pyspark.sql.types import StringType\n\nbucket = \"databricks-bq-123\"\n\n# make sure this dataset exists, or create is e.g. using GCP console or CLI\ntable = \"together.myTable\"\n\nmylist = [\"Google\", \"Databricks\", \"better together\"]\ndf = spark.createDataFrame(mylist, StringType())\ndf.write.format(\"bigquery\")  \\\n    .option(\"temporaryGcsBucket\", bucket) \\\n    .option(\"table\", table) \\\n    .mode(\"overwrite\") \\\n    .save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ebed82a-a108-41b5-8c70-3883352857aa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Python example BQ Storage API"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69f0d2c4-756c-48a6-9188-627631ddbd15"}}},{"cell_type":"code","source":["table = \"together.myTable\"\nspark.read.format(\"bigquery\")   \\\n    .option(\"table\", table)  \\\n    .load()  \\\n    .display()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c745578c-ca67-4c9f-8c6b-5ee2146cdf3e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Databricks"],["better together"],["Google"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"value","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>value</th></tr></thead><tbody><tr><td>Databricks</td></tr><tr><td>better together</td></tr><tr><td>Google</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Predicate Pushdown BQ Public Dataset with Explain"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e05bf8b-3dc3-4725-a6b7-67ebc3b00deb"}}},{"cell_type":"code","source":["%scala \n\n// shorter example is working with predicate pushdown\nval df = \n  spark.read.format(\"bigquery\")\n  .option(\"table\", \"bigquery-public-data.samples.natality\")\n  .load()\n  .filter(\"state = 'CA'\")\n  .filter(\"weight_pounds > 11\")\n\ndf.explain(\"extended\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"265a1868-24ed-48b5-9f81-2081d4f1bd17"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]","schema":{"type":"struct","fields":[{"name":"source_year","type":"long","nullable":false,"metadata":{"description":"Four-digit year of the birth. Example: 1975."}},{"name":"year","type":"long","nullable":true,"metadata":{"description":"Four-digit year of the birth. Example: 1975."}},{"name":"month","type":"long","nullable":true,"metadata":{"description":"Month index of the date of birth, where 1=January."}},{"name":"day","type":"long","nullable":true,"metadata":{"description":"Day of birth, starting from 1."}},{"name":"wday","type":"long","nullable":true,"metadata":{"description":"Day of the week, where 1 is Sunday and 7 is Saturday."}},{"name":"state","type":"string","nullable":true,"metadata":{"description":"The two character postal code for the state. Entries after 2004 do not include this value."}},{"name":"is_male","type":"boolean","nullable":false,"metadata":{"description":"TRUE if the child is male, FALSE if female."}},{"name":"child_race","type":"long","nullable":true,"metadata":{"description":"The race of the child. One of the following numbers:\n\n1 - White\n2 - Black\n3 - American Indian\n4 - Chinese\n5 - Japanese\n6 - Hawaiian\n7 - Filipino\n9 - Unknown/Other\n18 - Asian Indian\n28 - Korean\n39 - Samoan\n48 - Vietnamese"}},{"name":"weight_pounds","type":"double","nullable":true,"metadata":{"description":"Weight of the child, in pounds."}},{"name":"plurality","type":"long","nullable":true,"metadata":{"description":"How many children were born as a result of this pregnancy. twins=2, triplets=3, and so on."}},{"name":"apgar_1min","type":"long","nullable":true,"metadata":{"description":"Apgar scores measure the health of a newborn child on a scale from 0-10. Value after 1 minute. Available from 1978-2002."}},{"name":"apgar_5min","type":"long","nullable":true,"metadata":{"description":"Apgar scores measure the health of a newborn child on a scale from 0-10. Value after 5 minutes. Available from 1978-2002."}},{"name":"mother_residence_state","type":"string","nullable":true,"metadata":{"description":"The two-letter postal code of the mother's state of residence when the child was born."}},{"name":"mother_race","type":"long","nullable":true,"metadata":{"description":"Race of the mother. Same values as child_race."}},{"name":"mother_age","type":"long","nullable":true,"metadata":{"description":"Reported age of the mother when giving birth."}},{"name":"gestation_weeks","type":"long","nullable":true,"metadata":{"description":"The number of weeks of the pregnancy."}},{"name":"lmp","type":"string","nullable":true,"metadata":{"description":"Date of the last menstrual period in the format MMDDYYYY. Unknown values are recorded as \"99\" or \"9999\"."}},{"name":"mother_married","type":"boolean","nullable":true,"metadata":{"description":"True if the mother was married when she gave birth."}},{"name":"mother_birth_state","type":"string","nullable":true,"metadata":{"description":"The two-letter postal code of the mother's birth state."}},{"name":"cigarette_use","type":"boolean","nullable":true,"metadata":{"description":"True if the mother smoked cigarettes. Available starting 2003."}},{"name":"cigarettes_per_day","type":"long","nullable":true,"metadata":{"description":"Number of cigarettes smoked by the mother per day. Available starting 2003."}},{"name":"alcohol_use","type":"boolean","nullable":true,"metadata":{"description":"True if the mother used alcohol. Available starting 1989."}},{"name":"drinks_per_week","type":"long","nullable":true,"metadata":{"description":"Number of drinks per week consumed by the mother. Available starting 1989."}},{"name":"weight_gain_pounds","type":"long","nullable":true,"metadata":{"description":"Number of pounds gained by the mother during pregnancy."}},{"name":"born_alive_alive","type":"long","nullable":true,"metadata":{"description":"Number of children previously born to the mother who are now living."}},{"name":"born_alive_dead","type":"long","nullable":true,"metadata":{"description":"Number of children previously born to the mother who are now dead."}},{"name":"born_dead","type":"long","nullable":true,"metadata":{"description":"Number of children who were born dead (i.e. miscarriages)"}},{"name":"ever_born","type":"long","nullable":true,"metadata":{"description":"Total number of children to whom the woman has ever given birth (includes the current birth)."}},{"name":"father_race","type":"long","nullable":true,"metadata":{"description":"Race of the father. Same values as child_race."}},{"name":"father_age","type":"long","nullable":true,"metadata":{"description":"Age of the father when the child was born."}},{"name":"record_weight","type":"long","nullable":true,"metadata":{"description":"1 or 2, where 1 is a row from a full-reporting area, and 2 is a row from a 50% sample area."}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">== Parsed Logical Plan ==\n'Filter ('weight_pounds &gt; 11)\n+- Filter (state#116 = CA)\n   +- Relation[source_year#111L,year#112L,month#113L,day#114L,wday#115L,state#116,is_male#117,child_race#118L,weight_pounds#119,plurality#120L,apgar_1min#121L,apgar_5min#122L,mother_residence_state#123,mother_race#124L,mother_age#125L,gestation_weeks#126L,lmp#127,mother_married#128,mother_birth_state#129,cigarette_use#130,cigarettes_per_day#131L,alcohol_use#132,drinks_per_week#133L,weight_gain_pounds#134L,... 7 more fields] BigQueryRelation(bigquery-public-data.samples.natality\nnumRows=137,826,763\nnumBytes=23,562,717,384\n)\n\n== Analyzed Logical Plan ==\nsource_year: bigint, year: bigint, month: bigint, day: bigint, wday: bigint, state: string, is_male: boolean, child_race: bigint, weight_pounds: double, plurality: bigint, apgar_1min: bigint, apgar_5min: bigint, mother_residence_state: string, mother_race: bigint, mother_age: bigint, gestation_weeks: bigint, lmp: string, mother_married: boolean, mother_birth_state: string, cigarette_use: boolean, cigarettes_per_day: bigint, alcohol_use: boolean, drinks_per_week: bigint, weight_gain_pounds: bigint, ... 7 more fields\nFilter (weight_pounds#119 &gt; cast(11 as double))\n+- Filter (state#116 = CA)\n   +- Relation[source_year#111L,year#112L,month#113L,day#114L,wday#115L,state#116,is_male#117,child_race#118L,weight_pounds#119,plurality#120L,apgar_1min#121L,apgar_5min#122L,mother_residence_state#123,mother_race#124L,mother_age#125L,gestation_weeks#126L,lmp#127,mother_married#128,mother_birth_state#129,cigarette_use#130,cigarettes_per_day#131L,alcohol_use#132,drinks_per_week#133L,weight_gain_pounds#134L,... 7 more fields] BigQueryRelation(bigquery-public-data.samples.natality\nnumRows=137,826,763\nnumBytes=23,562,717,384\n)\n\n== Optimized Logical Plan ==\nFilter (((isnotnull(state#116) AND isnotnull(weight_pounds#119)) AND (state#116 = CA)) AND (weight_pounds#119 &gt; 11.0))\n+- Relation[source_year#111L,year#112L,month#113L,day#114L,wday#115L,state#116,is_male#117,child_race#118L,weight_pounds#119,plurality#120L,apgar_1min#121L,apgar_5min#122L,mother_residence_state#123,mother_race#124L,mother_age#125L,gestation_weeks#126L,lmp#127,mother_married#128,mother_birth_state#129,cigarette_use#130,cigarettes_per_day#131L,alcohol_use#132,drinks_per_week#133L,weight_gain_pounds#134L,... 7 more fields] BigQueryRelation(bigquery-public-data.samples.natality\nnumRows=137,826,763\nnumBytes=23,562,717,384\n)\n\n== Physical Plan ==\n*(1) Scan BigQueryRelation(bigquery-public-data.samples.natality\nnumRows=137,826,763\nnumBytes=23,562,717,384\n) [source_year#111L,year#112L,month#113L,day#114L,wday#115L,state#116,is_male#117,child_race#118L,weight_pounds#119,plurality#120L,apgar_1min#121L,apgar_5min#122L,mother_residence_state#123,mother_race#124L,mother_age#125L,gestation_weeks#126L,lmp#127,mother_married#128,mother_birth_state#129,cigarette_use#130,cigarettes_per_day#131L,alcohol_use#132,drinks_per_week#133L,weight_gain_pounds#134L,... 7 more fields] PushedFilters: [*IsNotNull(state), *IsNotNull(weight_pounds), *EqualTo(state,CA), *GreaterThan(weight_pounds,11.0)], ReadSchema: struct&lt;source_year:bigint,year:bigint,month:bigint,day:bigint,wday:bigint,state:string,is_male:bo...\n\ndf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [source_year: bigint, year: bigint ... 29 more fields]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Parsed Logical Plan ==\n'Filter ('weight_pounds &gt; 11)\n+- Filter (state#116 = CA)\n   +- Relation[source_year#111L,year#112L,month#113L,day#114L,wday#115L,state#116,is_male#117,child_race#118L,weight_pounds#119,plurality#120L,apgar_1min#121L,apgar_5min#122L,mother_residence_state#123,mother_race#124L,mother_age#125L,gestation_weeks#126L,lmp#127,mother_married#128,mother_birth_state#129,cigarette_use#130,cigarettes_per_day#131L,alcohol_use#132,drinks_per_week#133L,weight_gain_pounds#134L,... 7 more fields] BigQueryRelation(bigquery-public-data.samples.natality\nnumRows=137,826,763\nnumBytes=23,562,717,384\n)\n\n== Analyzed Logical Plan ==\nsource_year: bigint, year: bigint, month: bigint, day: bigint, wday: bigint, state: string, is_male: boolean, child_race: bigint, weight_pounds: double, plurality: bigint, apgar_1min: bigint, apgar_5min: bigint, mother_residence_state: string, mother_race: bigint, mother_age: bigint, gestation_weeks: bigint, lmp: string, mother_married: boolean, mother_birth_state: string, cigarette_use: boolean, cigarettes_per_day: bigint, alcohol_use: boolean, drinks_per_week: bigint, weight_gain_pounds: bigint, ... 7 more fields\nFilter (weight_pounds#119 &gt; cast(11 as double))\n+- Filter (state#116 = CA)\n   +- Relation[source_year#111L,year#112L,month#113L,day#114L,wday#115L,state#116,is_male#117,child_race#118L,weight_pounds#119,plurality#120L,apgar_1min#121L,apgar_5min#122L,mother_residence_state#123,mother_race#124L,mother_age#125L,gestation_weeks#126L,lmp#127,mother_married#128,mother_birth_state#129,cigarette_use#130,cigarettes_per_day#131L,alcohol_use#132,drinks_per_week#133L,weight_gain_pounds#134L,... 7 more fields] BigQueryRelation(bigquery-public-data.samples.natality\nnumRows=137,826,763\nnumBytes=23,562,717,384\n)\n\n== Optimized Logical Plan ==\nFilter (((isnotnull(state#116) AND isnotnull(weight_pounds#119)) AND (state#116 = CA)) AND (weight_pounds#119 &gt; 11.0))\n+- Relation[source_year#111L,year#112L,month#113L,day#114L,wday#115L,state#116,is_male#117,child_race#118L,weight_pounds#119,plurality#120L,apgar_1min#121L,apgar_5min#122L,mother_residence_state#123,mother_race#124L,mother_age#125L,gestation_weeks#126L,lmp#127,mother_married#128,mother_birth_state#129,cigarette_use#130,cigarettes_per_day#131L,alcohol_use#132,drinks_per_week#133L,weight_gain_pounds#134L,... 7 more fields] BigQueryRelation(bigquery-public-data.samples.natality\nnumRows=137,826,763\nnumBytes=23,562,717,384\n)\n\n== Physical Plan ==\n*(1) Scan BigQueryRelation(bigquery-public-data.samples.natality\nnumRows=137,826,763\nnumBytes=23,562,717,384\n) [source_year#111L,year#112L,month#113L,day#114L,wday#115L,state#116,is_male#117,child_race#118L,weight_pounds#119,plurality#120L,apgar_1min#121L,apgar_5min#122L,mother_residence_state#123,mother_race#124L,mother_age#125L,gestation_weeks#126L,lmp#127,mother_married#128,mother_birth_state#129,cigarette_use#130,cigarettes_per_day#131L,alcohol_use#132,drinks_per_week#133L,weight_gain_pounds#134L,... 7 more fields] PushedFilters: [*IsNotNull(state), *IsNotNull(weight_pounds), *EqualTo(state,CA), *GreaterThan(weight_pounds,11.0)], ReadSchema: struct&lt;source_year:bigint,year:bigint,month:bigint,day:bigint,wday:bigint,state:string,is_male:bo...\n\ndf: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [source_year: bigint, year: bigint ... 29 more fields]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Spark reading from BQ query with Storage API"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a36ca986-225a-4750-ad29-9837619d0e87"}}},{"cell_type":"code","source":["%scala\n\nval table = \"bigquery-public-data.samples.shakespeare\"\nval tempLocation = \"databricks_testing_frank\"\n\n// read the entire table into a DataFrame\nval df1 = spark.read.format(\"bigquery\").option(\"table\", table).load()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"426070dd-3f65-4100-b88e-ba336e0b61cc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df1","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"word","type":"string","nullable":false,"metadata":{"description":"A single unique word (where whitespace is the delimiter) extracted from a corpus."}},{"name":"word_count","type":"long","nullable":false,"metadata":{"description":"The number of times this word appears in this corpus."}},{"name":"corpus","type":"string","nullable":false,"metadata":{"description":"The work from which this word was extracted."}},{"name":"corpus_date","type":"long","nullable":false,"metadata":{"description":"The year in which this corpus was published."}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">table: String = bigquery-public-data.samples.shakespeare\ntempLocation: String = databricks_testing_frank\ndf1: org.apache.spark.sql.DataFrame = [word: string, word_count: bigint ... 2 more fields]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">table: String = bigquery-public-data.samples.shakespeare\ntempLocation: String = databricks_testing_frank\ndf1: org.apache.spark.sql.DataFrame = [word: string, word_count: bigint ... 2 more fields]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Shakespear Histogram with Query executed on BQ"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5fc7578-1920-44e6-b5ca-49018c6e49cb"}}},{"cell_type":"code","source":["%scala\n\n// public dataset \nval table = \"bigquery-public-data.samples.shakespeare\"\n\n//val existing dataset where GCP user has table creation permission\nval tempLocation = \"mdataset\"\n// query string\nval q = s\"\"\"SELECT word, SUM(word_count) AS word_count FROM ${table} \n        GROUP BY word ORDER BY word_count DESC LIMIT 10 \"\"\"\n\n// read the result of a BigQuery SQL query into a DataFrame\nval df2 =\n\tspark.read.format(\"bigquery\")\n    .option(\"query\", q)\n    .option(\"materializationDataset\", tempLocation)\n\t.load()\n\n// show the top 5 common words in shakespeare\ndf2.show(5)\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da86d56d-5fd3-43cc-b3d9-d35c69aa87d8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df2","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"word","type":"string","nullable":true,"metadata":{}},{"name":"word_count","type":"long","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+----+----------+\n|word|word_count|\n+----+----------+\n| the|     25568|\n|   I|     21028|\n| and|     19649|\n|  to|     17361|\n|  of|     16438|\n+----+----------+\nonly showing top 5 rows\n\ntable: String = bigquery-public-data.samples.shakespeare\ntempLocation: String = mdataset\nq: String =\n&quot;SELECT word, SUM(word_count) AS word_count FROM bigquery-public-data.samples.shakespeare\n        GROUP BY word ORDER BY word_count DESC LIMIT 10 &quot;\ndf2: org.apache.spark.sql.DataFrame = [word: string, word_count: bigint]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----------+\nword|word_count|\n+----+----------+\n the|     25568|\n   I|     21028|\n and|     19649|\n  to|     17361|\n  of|     16438|\n+----+----------+\nonly showing top 5 rows\n\ntable: String = bigquery-public-data.samples.shakespeare\ntempLocation: String = mdataset\nq: String =\n&quot;SELECT word, SUM(word_count) AS word_count FROM bigquery-public-data.samples.shakespeare\n        GROUP BY word ORDER BY word_count DESC LIMIT 10 &quot;\ndf2: org.apache.spark.sql.DataFrame = [word: string, word_count: bigint]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["table = \"bigquery-public-data.samples.shakespeare\"\ndf = spark.read.format(\"bigquery\").option(\"table\",table).load()\ndf.show()\ndf.createOrReplaceTempView(\"words\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9fddf414-1abc-4eae-b32c-e20f507f3b86"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+----------+-------+-----------+\n|     word|word_count| corpus|corpus_date|\n+---------+----------+-------+-----------+\n|     LVII|         1|sonnets|          0|\n|   augurs|         1|sonnets|          0|\n|   dimm&#39;d|         1|sonnets|          0|\n|  plagues|         1|sonnets|          0|\n|  treason|         1|sonnets|          0|\n|  surmise|         1|sonnets|          0|\n|     heed|         1|sonnets|          0|\n|Unthrifty|         1|sonnets|          0|\n|  quality|         1|sonnets|          0|\n| wherever|         1|sonnets|          0|\n|        C|         1|sonnets|          0|\n|        L|         1|sonnets|          0|\n|imaginary|         1|sonnets|          0|\n|        H|         1|sonnets|          0|\n|   relief|         1|sonnets|          0|\n|        W|         1|sonnets|          0|\n|        V|         1|sonnets|          0|\n|  advised|         1|sonnets|          0|\n|     grey|         1|sonnets|          0|\n|        X|         1|sonnets|          0|\n+---------+----------+-------+-----------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+----------+-------+-----------+\n     word|word_count| corpus|corpus_date|\n+---------+----------+-------+-----------+\n     LVII|         1|sonnets|          0|\n   augurs|         1|sonnets|          0|\n   dimm&#39;d|         1|sonnets|          0|\n  plagues|         1|sonnets|          0|\n  treason|         1|sonnets|          0|\n  surmise|         1|sonnets|          0|\n     heed|         1|sonnets|          0|\nUnthrifty|         1|sonnets|          0|\n  quality|         1|sonnets|          0|\n wherever|         1|sonnets|          0|\n        C|         1|sonnets|          0|\n        L|         1|sonnets|          0|\nimaginary|         1|sonnets|          0|\n        H|         1|sonnets|          0|\n   relief|         1|sonnets|          0|\n        W|         1|sonnets|          0|\n        V|         1|sonnets|          0|\n  advised|         1|sonnets|          0|\n     grey|         1|sonnets|          0|\n        X|         1|sonnets|          0|\n+---------+----------+-------+-----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Spark SQL: Shakespear Histo"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93e17530-5c44-4e95-91de-e2dd7cabdb0b"}}},{"cell_type":"code","source":["# perform word count\nwordCountDf = spark.sql(\"SELECT word, SUM(word_count) AS word_count FROM words GROUP BY word ORDER BY word_count DESC LIMIT 10\")\n\ndisplay(wordCountDf)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5316295-76ea-4027-bd23-492d0d4632ec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["the",25568],["I",21028],["and",19649],["to",17361],["of",16438],["a",13409],["you",12527],["my",11291],["in",10589],["is",8735]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"word","type":"\"string\"","metadata":"{\"description\":\"A single unique word (where whitespace is the delimiter) extracted from a corpus.\"}"},{"name":"word_count","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>word</th><th>word_count</th></tr></thead><tbody><tr><td>the</td><td>25568</td></tr><tr><td>I</td><td>21028</td></tr><tr><td>and</td><td>19649</td></tr><tr><td>to</td><td>17361</td></tr><tr><td>of</td><td>16438</td></tr><tr><td>a</td><td>13409</td></tr><tr><td>you</td><td>12527</td></tr><tr><td>my</td><td>11291</td></tr><tr><td>in</td><td>10589</td></tr><tr><td>is</td><td>8735</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Shakespeare WordCount. SQL query executed on BQ with materializationDataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d130b5ce-52a5-44fc-8bd6-0f699eb1db20"}}},{"cell_type":"code","source":["table = \"bigquery-public-data.samples.shakespeare\"\ntempLocation = \"mdataset\"\nquery = \"SELECT count(1) FROM {table}\".format(table=table)\n\n# load the result of a SQL query on BigQuery into a DataFrame\ndf = spark.read.format(\"bigquery\") \\\n.option(\"materializationDataset\", tempLocation) \\\n.option(\"query\", query) \\\n.load() \\\n.collect()\n\n# display(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15404e7d-8302-40e1-831e-9d740c2e3845"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Covid-19 Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64f7197a-3f94-4421-bdee-829e6ad63aa1"}}},{"cell_type":"code","source":["\n\ntable = \"bigquery-public-data.covid19_nyt.excess_deaths\"\ndf = spark.read.format(\"bigquery\").option(\"table\",table).load()\ndf.createOrReplaceTempView(\"covid19_nyt_excess_deaths\")\n#df.display()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fc479c3-77cc-4d41-91c7-c5c2fcb3227d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nselect country, sum(excess_deaths) as excess_deaths from covid19_nyt_excess_deaths group by country\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"821a38ba-7b54-4837-8400-1ee38156151a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Russia",23445],["Sweden",7469],["Turkey",15405],["Germany",8072],["France",45917],["Belgium",14281],["Ecuador",37479],["Finland",1113],["Peru",107023],["India",8338],["United States",377605],["Chile",14253],["Bolivia",29469],["Italy",80025],["Norway",-322],["Spain",68362],["Denmark",-879],["Ireland",-31],["Thailand",-922],["Israel",2405],["South Korea",797],["Mexico",227295],["Indonesia",17535],["Switzerland",6523],["Czech Republic",11008],["Brazil",200843],["Japan",-30734],["Poland",44006],["Portugal",8731],["Austria",6877],["South Africa",58813],["Colombia",33168],["Hungary",4860],["United Kingdom",74615],["Netherlands",12957]],"plotOptions":{"displayType":"plotlyBar","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"country","type":"\"string\"","metadata":"{\"description\":\"\"}"},{"name":"excess_deaths","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>country</th><th>excess_deaths</th></tr></thead><tbody><tr><td>Russia</td><td>23445</td></tr><tr><td>Sweden</td><td>7469</td></tr><tr><td>Turkey</td><td>15405</td></tr><tr><td>Germany</td><td>8072</td></tr><tr><td>France</td><td>45917</td></tr><tr><td>Belgium</td><td>14281</td></tr><tr><td>Ecuador</td><td>37479</td></tr><tr><td>Finland</td><td>1113</td></tr><tr><td>Peru</td><td>107023</td></tr><tr><td>India</td><td>8338</td></tr><tr><td>United States</td><td>377605</td></tr><tr><td>Chile</td><td>14253</td></tr><tr><td>Bolivia</td><td>29469</td></tr><tr><td>Italy</td><td>80025</td></tr><tr><td>Norway</td><td>-322</td></tr><tr><td>Spain</td><td>68362</td></tr><tr><td>Denmark</td><td>-879</td></tr><tr><td>Ireland</td><td>-31</td></tr><tr><td>Thailand</td><td>-922</td></tr><tr><td>Israel</td><td>2405</td></tr><tr><td>South Korea</td><td>797</td></tr><tr><td>Mexico</td><td>227295</td></tr><tr><td>Indonesia</td><td>17535</td></tr><tr><td>Switzerland</td><td>6523</td></tr><tr><td>Czech Republic</td><td>11008</td></tr><tr><td>Brazil</td><td>200843</td></tr><tr><td>Japan</td><td>-30734</td></tr><tr><td>Poland</td><td>44006</td></tr><tr><td>Portugal</td><td>8731</td></tr><tr><td>Austria</td><td>6877</td></tr><tr><td>South Africa</td><td>58813</td></tr><tr><td>Colombia</td><td>33168</td></tr><tr><td>Hungary</td><td>4860</td></tr><tr><td>United Kingdom</td><td>74615</td></tr><tr><td>Netherlands</td><td>12957</td></tr></tbody></table></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"TestGCP","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3545176844457056}},"nbformat":4,"nbformat_minor":0}
